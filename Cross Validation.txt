######### PseudoCode for Cross Validation #########

---------
5 folds:

To get the % folds I ran the script which is given by movie lens. I modified the script to take ratings.csv from the 20M dataset as its input and given me 5 folds.

Files Generated:
Training :r1.train, r2.train, r3.train, r4.train, r5.train
Test     :r1.test, r2.test, r3.test, r4.test, r5.test

Script Output:
Apple-Macbook:~ Amogh$ sh /Users/apple/Downloads/split_ratings.sh 
ratings count: 20000264
set size: 4000052
remainder: 4
head: illegal line count -- 0
r1.test created.  4000052 lines.
r1.train created.  16000212 lines.
r2.test created.  4000052 lines.
r2.train created.  16000212 lines.
r3.test created.  4000052 lines.
r3.train created.  16000212 lines.
r4.test created.  4000052 lines.
r4.train created.  16000212 lines.
r5.test created.  4000056 lines.
r5.train created.  16000208 lines.

---------

# Start Cross Validation

Full_ratings_rdd <= sc.textfile(ratings.csv)

# The following function to create the prediction ratings and groud truth value pairs, for calculating MAP value
def map_calc(x):
	groundTruthList <- groundTruthList.append(x[1]) if x[1]>=3
	predictedRatingList <- predictedRatingList.append(x[2]) if x[2]>=3
	sort (predictedRatingList,groundTruthList)
	EMIT TUPLE(predictedRatingList,groundTruthList)
	
For each train_file in training:
	training_data <= Full_ratings_rdd.subtract(tr_data_rdd)   	# taking each remaining protion of the whole data (by subtracting) as the training data

	# Now train the data with the best model that is got by the tuning the loss function with ALS (This is done in the recommendation.py file) 
	model <= ALS.train(training_data, 12, seed=5L, iterations=iterations, lambda_=reg_param)

	# make the predictions with the corresponding test file which is generated by the movielens script (5 folds).
	predictions <= model.predictAll(test_data).map(lambda r: ((r[0], r[1]), r[2]))

	# put the actual ratings and predictions together to get the required metrics (RMSE, MSE, MAP)
	rates_and_preds <= test_data_rdd.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)

	Calculate(MSE) <- sum(MSE)
	Calculate(RMSE) <- sum(RMSE)		

	PREPROCESS(rates_and_preds)			# Step 1 and Step 2 in the code file -> to get the prediction and ground truth pairs
	Calculate(MAP) <- sum(MAP)			#This is calculated with the help of the function(map_calc) defined above

Emit sum(MSE)/5 		# this would be the average valuse of MSE, after Cross Validation
Emit sum(RMSE)/5		# this would be the average valuse of RMSE, after Cross Validation
Emit sum(MAP)/5			# this would be the average valuse of MAP, after Cross Validation
